{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'H:\\RediMinds\\VCQI'\n",
    "train = pd.read_csv(input_path+\"\\VCQI_clean_train.csv\")\n",
    "test = pd.read_csv(input_path+\"\\VCQI_clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(labels='INTRA_OP_COMPLICATIONS', axis = 'columns').copy()\n",
    "y_train = train['INTRA_OP_COMPLICATIONS'].copy()\n",
    "x_test = test.drop(labels='INTRA_OP_COMPLICATIONS', axis = 'columns').copy()\n",
    "y_test = test['INTRA_OP_COMPLICATIONS'].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% pos labels train 0.06\n",
      "% pos labels test 0.06\n"
     ]
    }
   ],
   "source": [
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Cataegorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ONE HOT CODE data for training\n",
    "\n",
    "# Create dummy variables\n",
    "with open (input_path+'\\cat_col', 'rb') as fp:\n",
    "    cat_col = pickle.load(fp)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "\n",
    "one_hot_encoded_array = encoder.fit_transform(x_train[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_train_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_train = x_train.merge(x_train_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_train = x_train.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "one_hot_encoded_array = encoder.transform(x_test[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_test_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_test = x_test.merge(x_test_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_test = x_test.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in trainset 1187\n",
      "Number records in testset 510\n",
      "% pos labels train 0.06\n",
      "% pos labels test 0.06\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in trainset {}\".format(len(x_train)))\n",
    "print(\"Number records in testset {}\".format(len(x_test)))\n",
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for logist Classifier\n",
    "numeric_features = x_train.select_dtypes('float').columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5327648114901257, 1: 8.13013698630137}\n"
     ]
    }
   ],
   "source": [
    "# compute weight to account for class imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=y_train.unique(), y = y_train)\n",
    "weights\n",
    "class_weight = {0: weights[0] , 1: weights[1]}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(dropout_rate, neurons, learning_rate):\n",
    "    from numpy.random import seed\n",
    "    seed(123)\n",
    "    tf.random.set_seed(123)\n",
    "    tf.keras.backend.clear_session()\n",
    "   \n",
    "    # input layer\n",
    "    input_layer = keras.layers.Input(shape=(x_train.shape[1],), name = \"input_layer\")\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_1',activation='relu')(input_layer)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_1', seed = 42)(x)\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_2',activation='relu')(x)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_2', seed = 42)(x)\n",
    "    main_output = keras.layers.Dense(1, activation='sigmoid',name='main_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs= input_layer, outputs=main_output)\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.AUC(curve = 'ROC',name = 'AUC_ROC'),\n",
    "                           tf.keras.metrics.AUC(curve = 'PR', name = 'AUC_PR')],\n",
    "                  )\n",
    "\n",
    "    # Keras callback. The patience parameter is the amount of epochs to check for improvement\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=nn_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "parameter_dist = {'classifier__dropout_rate':[0.1,0.2,0.3,0.4,0.5],\n",
    "                  'classifier__epochs':[10,20,30],\n",
    "                  'classifier__neurons':[128, 256],\n",
    "                  'classifier__learning_rate': [0.01, 0.001, 0.0001],\n",
    "                 }\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      #('pca',PCA()),\n",
    "                      ('classifier', model)])\n",
    "model = GridSearchCV(clf,parameter_dist,n_jobs= 1,scoring= 'average_precision', cv = 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 900 out of 900 | elapsed: 59.5min finished\n",
      "H:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('scaler',\n",
       "                                                                                          StandardScaler(copy=True,\n",
       "                                                                                                         with_mean=True,\n",
       "                                                                                                         with_std=True))],\n",
       "                                                                                  verbose=False),\n",
       "                                                                         ['AGEATSURGERY...\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001AE7093B7F0>)],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'classifier__dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'classifier__epochs': [10, 20, 30],\n",
       "                         'classifier__learning_rate': [0.01, 0.001, 0.0001],\n",
       "                         'classifier__neurons': [128, 256]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='average_precision', verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "#early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min',restore_best_weights=True)\n",
    "model.fit(x_train,y_train, classifier__class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = pd.DataFrame(model.predict(x_test), columns=['pred_label'])\n",
    "results_nn['pred_prob'] =  pd.DataFrame(model.predict_proba(x_test))[1]\n",
    "results_nn['true_label'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.303519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.428737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.769504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.874265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.109123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.254650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.398562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.126597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.121506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.359638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.166041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.465380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.180341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.192524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.753872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.179226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.208232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>0.546386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>0.223747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.222287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.086785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.467565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0.399339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>0.090021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0.114935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.474277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0.073986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>0.361919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0</td>\n",
       "      <td>0.183799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0</td>\n",
       "      <td>0.147672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0</td>\n",
       "      <td>0.110239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_label  pred_prob  true_label\n",
       "0             0   0.303519           0\n",
       "1             0   0.428737           0\n",
       "2             0   0.038576           0\n",
       "3             1   0.769504           0\n",
       "4             0   0.128515           0\n",
       "5             1   0.874265           0\n",
       "6             0   0.188700           0\n",
       "7             1   0.548030           0\n",
       "8             0   0.109123           0\n",
       "9             0   0.254650           0\n",
       "10            0   0.398562           0\n",
       "11            0   0.126597           0\n",
       "12            0   0.121506           0\n",
       "13            0   0.042261           0\n",
       "14            0   0.089595           0\n",
       "15            0   0.359638           0\n",
       "16            0   0.268050           0\n",
       "17            1   0.500855           0\n",
       "18            0   0.166041           0\n",
       "19            0   0.024749           0\n",
       "20            0   0.465380           0\n",
       "21            0   0.180341           0\n",
       "22            0   0.034146           0\n",
       "23            0   0.040767           0\n",
       "24            0   0.092734           1\n",
       "25            0   0.192524           0\n",
       "26            1   0.753872           1\n",
       "27            0   0.179226           0\n",
       "28            0   0.208232           0\n",
       "29            0   0.188548           0\n",
       "..          ...        ...         ...\n",
       "480           0   0.104662           0\n",
       "481           1   0.546386           0\n",
       "482           0   0.058724           0\n",
       "483           0   0.223747           0\n",
       "484           0   0.100514           0\n",
       "485           0   0.222287           0\n",
       "486           1   0.676828           1\n",
       "487           0   0.017652           0\n",
       "488           0   0.086785           0\n",
       "489           1   0.516733           0\n",
       "490           0   0.467565           0\n",
       "491           0   0.399339           0\n",
       "492           0   0.090021           0\n",
       "493           0   0.008892           0\n",
       "494           0   0.051281           0\n",
       "495           1   0.615501           0\n",
       "496           0   0.114935           0\n",
       "497           0   0.474277           0\n",
       "498           0   0.073986           0\n",
       "499           0   0.075707           0\n",
       "500           0   0.361919           0\n",
       "501           0   0.049123           1\n",
       "502           0   0.013761           0\n",
       "503           0   0.113129           0\n",
       "504           0   0.431767           0\n",
       "505           0   0.183799           0\n",
       "506           0   0.137892           0\n",
       "507           0   0.147672           0\n",
       "508           0   0.110239           0\n",
       "509           1   0.964755           1\n",
       "\n",
       "[510 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Balanced Accuracy: \n",
      "0.7442925449525221\n",
      "\n",
      " Confusion Matrix : \n",
      "[[404  75]\n",
      " [ 11  20]]\n",
      "\n",
      " Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90       479\n",
      "           1       0.21      0.65      0.32        31\n",
      "\n",
      "    accuracy                           0.83       510\n",
      "   macro avg       0.59      0.74      0.61       510\n",
      "weighted avg       0.93      0.83      0.87       510\n",
      "\n",
      "\n",
      " AUC-ROC: \n",
      "0.7628123105933059\n",
      "\n",
      " PR-ROC: \n",
      "0.37920110089235365\n"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork Score Raw Data\n",
    "print(\"\\n Model Balanced Accuracy: \\n\" + str(metrics.balanced_accuracy_score(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Confusion Matrix : \\n\"+str(metrics.confusion_matrix(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Classification Report: \\n\"+ str(metrics.classification_report(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n AUC-ROC: \\n\"+ str(metrics.roc_auc_score(results_nn['true_label'], results_nn['pred_prob'])))\n",
    "\n",
    "\n",
    "def calc_aucpr_data(result):\n",
    "    y_ACTUAL = result['true_label']\n",
    "    scores_prob = result['pred_prob']\n",
    "    yhat = result['pred_label']\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "    prc_auc = metrics.auc(recall,precision)\n",
    "    return prc_auc\n",
    "\n",
    "print(\"\\n PR-ROC: \\n\"+ str(calc_aucpr_data(results_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.81446209, 3.10278785, 2.81238949, 3.01336679, 2.71904771,\n",
       "        3.11780221, 3.55218678, 4.18073568, 3.55527909, 4.10516019,\n",
       "        3.49378242, 4.10680654, 4.28154383, 5.16855371, 4.38600268,\n",
       "        5.21682134, 4.28375459, 5.18704181, 2.701279  , 3.09850647,\n",
       "        2.80403333, 3.0834707 , 2.81783035, 3.05255859, 3.65938497,\n",
       "        4.18097591, 3.47556567, 4.22416353, 3.67564158, 4.18563895,\n",
       "        4.39437141, 5.29347014, 4.34325588, 5.290101  , 4.53883002,\n",
       "        5.24931743, 2.69170287, 2.96633468, 2.72553389, 3.04575527,\n",
       "        2.80471184, 3.07952633, 3.62086947, 4.22815499, 3.56972272,\n",
       "        4.20362413, 3.66601746, 4.10474744, 4.31983225, 5.19442096,\n",
       "        4.31463044, 5.23836875, 4.20738626, 6.24431753, 3.77756803,\n",
       "        3.08045752, 2.7796658 , 3.15667512, 2.89669068, 3.12261808,\n",
       "        3.56165488, 4.25256577, 3.46545327, 4.17636499, 3.64595397,\n",
       "        4.21456742, 4.25854921, 5.15598319, 4.19820025, 5.05014856,\n",
       "        4.34557583, 5.0409287 , 2.6844682 , 3.03290212, 2.75456338,\n",
       "        3.04374576, 2.77383149, 3.05135992, 3.56468759, 4.12372763,\n",
       "        3.4838989 , 4.17846904, 3.57609634, 4.19673398, 4.38034711,\n",
       "        5.23185189, 4.26497161, 5.16713481, 4.24656301, 5.13833013]),\n",
       " 'std_fit_time': array([0.2252312 , 0.20245965, 0.18083914, 0.1394939 , 0.17763464,\n",
       "        0.21428883, 0.12149716, 0.21405003, 0.22212467, 0.21214721,\n",
       "        0.16462968, 0.14579318, 0.18160635, 0.14630519, 0.24026988,\n",
       "        0.18891937, 0.14747984, 0.17568937, 0.26818592, 0.19457649,\n",
       "        0.1970454 , 0.18749417, 0.20375194, 0.1548672 , 0.20319058,\n",
       "        0.23118093, 0.19513387, 0.21188991, 0.24988972, 0.26368923,\n",
       "        0.16774224, 0.26128213, 0.18623313, 0.20011872, 0.25025142,\n",
       "        0.22752074, 0.14373738, 0.17840045, 0.14744752, 0.14978868,\n",
       "        0.24102665, 0.19276948, 0.22127092, 0.22497857, 0.18068399,\n",
       "        0.20892689, 0.23094369, 0.15345828, 0.1747701 , 0.22369353,\n",
       "        0.16732817, 0.22483807, 0.19903396, 1.28184527, 1.01981345,\n",
       "        0.1936817 , 0.14762911, 0.16123819, 0.20958404, 0.2508544 ,\n",
       "        0.18052591, 0.17217595, 0.19246739, 0.16106063, 0.16421181,\n",
       "        0.23476913, 0.17271288, 0.21059414, 0.18670457, 0.19717462,\n",
       "        0.27620372, 0.17563983, 0.18200951, 0.19264887, 0.21730776,\n",
       "        0.21305675, 0.17819742, 0.18216633, 0.19938124, 0.22101098,\n",
       "        0.16012181, 0.22172126, 0.26373386, 0.15649339, 0.21083255,\n",
       "        0.25158967, 0.21200857, 0.13687674, 0.17209354, 0.21403467]),\n",
       " 'mean_score_time': array([0.08818707, 0.11638718, 0.0890312 , 0.08295367, 0.08293386,\n",
       "        0.08374445, 0.08416841, 0.0851249 , 0.11401997, 0.08363242,\n",
       "        0.1262531 , 0.08284347, 0.08293951, 0.11441305, 0.08306539,\n",
       "        0.08574162, 0.11135271, 0.08553698, 0.10938444, 0.08767343,\n",
       "        0.08568113, 0.08435574, 0.08424528, 0.08471403, 0.08372979,\n",
       "        0.11607411, 0.08237085, 0.09111586, 0.09062395, 0.08556077,\n",
       "        0.08432057, 0.09318149, 0.08419802, 0.08958843, 0.0905477 ,\n",
       "        0.0868036 , 0.08021441, 0.08313963, 0.08155844, 0.08802269,\n",
       "        0.08581657, 0.08557639, 0.08234148, 0.0868468 , 0.11143575,\n",
       "        0.09048362, 0.08757429, 0.08238049, 0.08272874, 0.08572555,\n",
       "        0.08425958, 0.08437767, 0.08178561, 0.15708413, 0.15755489,\n",
       "        0.08871887, 0.08545842, 0.08803797, 0.08457484, 0.08392055,\n",
       "        0.08323584, 0.11525736, 0.08208587, 0.08363473, 0.08310566,\n",
       "        0.09150951, 0.08409858, 0.0831337 , 0.07983186, 0.08098474,\n",
       "        0.0937351 , 0.11136684, 0.08402081, 0.08370404, 0.08883474,\n",
       "        0.08522246, 0.08681388, 0.08419499, 0.0810904 , 0.08974996,\n",
       "        0.08324804, 0.11850786, 0.08749595, 0.08310196, 0.08482847,\n",
       "        0.08715553, 0.08137059, 0.08520787, 0.11794817, 0.08329411]),\n",
       " 'std_score_time': array([0.00847035, 0.08780056, 0.00763337, 0.00257723, 0.00434707,\n",
       "        0.0040461 , 0.00495592, 0.00472986, 0.08778315, 0.00352842,\n",
       "        0.13149011, 0.00350458, 0.00254178, 0.08976841, 0.00391026,\n",
       "        0.00924011, 0.08898418, 0.00446244, 0.08558583, 0.00572787,\n",
       "        0.00496633, 0.00438274, 0.00591844, 0.00390064, 0.00320002,\n",
       "        0.08725431, 0.00354339, 0.00890312, 0.00812775, 0.00420521,\n",
       "        0.00364332, 0.02005504, 0.00318623, 0.00720061, 0.01264372,\n",
       "        0.00945636, 0.00114758, 0.00419106, 0.00386912, 0.00869974,\n",
       "        0.00934843, 0.00485551, 0.00145336, 0.00644889, 0.0870223 ,\n",
       "        0.01168861, 0.00771457, 0.00231248, 0.00418218, 0.00926113,\n",
       "        0.00636586, 0.0051028 , 0.00367109, 0.07364256, 0.09577038,\n",
       "        0.00687961, 0.0066157 , 0.00444371, 0.00331968, 0.00354194,\n",
       "        0.00279544, 0.09044655, 0.006953  , 0.00301565, 0.00267777,\n",
       "        0.01522817, 0.0040004 , 0.00459234, 0.0024909 , 0.00146226,\n",
       "        0.0311953 , 0.08689998, 0.01170126, 0.00564947, 0.00869275,\n",
       "        0.00663914, 0.01007459, 0.00309343, 0.00209857, 0.01582525,\n",
       "        0.00351743, 0.09955967, 0.00721403, 0.00377661, 0.0048521 ,\n",
       "        0.00721194, 0.00313001, 0.01263236, 0.10173784, 0.00379833]),\n",
       " 'param_classifier__dropout_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 30, 30,\n",
       "                    30, 30, 30, 30, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 30, 30, 30, 30, 30, 30, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 10, 10,\n",
       "                    10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30,\n",
       "                    30, 30, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__learning_rate': masked_array(data=[0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001, 0.01, 0.01,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001, 0.01,\n",
       "                    0.01, 0.001, 0.001, 0.0001, 0.0001, 0.01, 0.01, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001, 0.01,\n",
       "                    0.01, 0.001, 0.001, 0.0001, 0.0001, 0.01, 0.01, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__neurons': masked_array(data=[128, 256, 128, 256, 128, 256, 128, 256, 128, 256, 128,\n",
       "                    256, 128, 256, 128, 256, 128, 256, 128, 256, 128, 256,\n",
       "                    128, 256, 128, 256, 128, 256, 128, 256, 128, 256, 128,\n",
       "                    256, 128, 256, 128, 256, 128, 256, 128, 256, 128, 256,\n",
       "                    128, 256, 128, 256, 128, 256, 128, 256, 128, 256, 128,\n",
       "                    256, 128, 256, 128, 256, 128, 256, 128, 256, 128, 256,\n",
       "                    128, 256, 128, 256, 128, 256, 128, 256, 128, 256, 128,\n",
       "                    256, 128, 256, 128, 256, 128, 256, 128, 256, 128, 256,\n",
       "                    128, 256],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.1,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.2,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.3,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.4,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 10,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 20,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.01,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.001,\n",
       "   'classifier__neurons': 256},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 128},\n",
       "  {'classifier__dropout_rate': 0.5,\n",
       "   'classifier__epochs': 30,\n",
       "   'classifier__learning_rate': 0.0001,\n",
       "   'classifier__neurons': 256}],\n",
       " 'split0_test_score': array([0.27906547, 0.37886598, 0.43557032, 0.36189799, 0.41103864,\n",
       "        0.39442196, 0.19315347, 0.26861345, 0.3054155 , 0.31068262,\n",
       "        0.40484143, 0.41204416, 0.25262171, 0.26701681, 0.38765841,\n",
       "        0.3160084 , 0.4055655 , 0.41370751, 0.26736198, 0.32597392,\n",
       "        0.42556648, 0.37482712, 0.40534513, 0.39895592, 0.27651727,\n",
       "        0.22652   , 0.31223766, 0.33003371, 0.37508418, 0.4196011 ,\n",
       "        0.1743345 , 0.34845054, 0.32691162, 0.42663503, 0.40119464,\n",
       "        0.42146864, 0.34180249, 0.3441152 , 0.42242279, 0.32163221,\n",
       "        0.38964828, 0.39895623, 0.18099604, 0.41481922, 0.29945695,\n",
       "        0.33242123, 0.38769482, 0.41594316, 0.28183082, 0.25850032,\n",
       "        0.37487471, 0.30809614, 0.37160719, 0.42054506, 0.30954527,\n",
       "        0.45449458, 0.39583812, 0.42943064, 0.32266548, 0.39686892,\n",
       "        0.39075409, 0.33827812, 0.41423847, 0.29868284, 0.3988587 ,\n",
       "        0.39460315, 0.35430576, 0.35104342, 0.4067908 , 0.30638501,\n",
       "        0.37901818, 0.41750027, 0.30671137, 0.37613571, 0.31145759,\n",
       "        0.38705795, 0.28510933, 0.40041664, 0.45543548, 0.35964731,\n",
       "        0.40422704, 0.39986548, 0.4086341 , 0.4052179 , 0.37489012,\n",
       "        0.48359459, 0.42250942, 0.31319851, 0.38317395, 0.3927886 ]),\n",
       " 'split1_test_score': array([0.49908964, 0.20575572, 0.53052632, 0.5591133 , 0.54782609,\n",
       "        0.54344322, 0.55420981, 0.56994182, 0.54333333, 0.52636364,\n",
       "        0.63477547, 0.54076923, 0.42961548, 0.39729225, 0.50050862,\n",
       "        0.44873669, 0.68477547, 0.51833333, 0.48312864, 0.53901235,\n",
       "        0.55687075, 0.52403477, 0.46666667, 0.53458333, 0.42170385,\n",
       "        0.26840336, 0.52714286, 0.49729225, 0.62373358, 0.54861329,\n",
       "        0.49917259, 0.6464986 , 0.5012605 , 0.32056653, 0.67871486,\n",
       "        0.51698889, 0.22243108, 0.49244808, 0.52755952, 0.52067669,\n",
       "        0.44803922, 0.53372549, 0.48814192, 0.3214986 , 0.55741935,\n",
       "        0.52382681, 0.59065637, 0.51260823, 0.37031413, 0.129534  ,\n",
       "        0.50717703, 0.44173669, 0.67916667, 0.52400782, 0.50485348,\n",
       "        0.54967643, 0.47067901, 0.51704545, 0.40703812, 0.52039216,\n",
       "        0.41362984, 0.45598291, 0.53452547, 0.53707792, 0.48467262,\n",
       "        0.53428571, 0.49807234, 0.52340336, 0.4940931 , 0.41331388,\n",
       "        0.59646383, 0.55939394, 0.58075269, 0.56607958, 0.55293651,\n",
       "        0.55561878, 0.34109972, 0.38205882, 0.49531151, 0.48700801,\n",
       "        0.50777778, 0.60154712, 0.46656763, 0.53988796, 0.47945599,\n",
       "        0.41143366, 0.49020204, 0.50562448, 0.565625  , 0.52779974]),\n",
       " 'split2_test_score': array([0.67324415, 0.68939394, 0.66190476, 0.55014985, 0.69965035,\n",
       "        0.65555556, 0.72828283, 0.42417582, 0.67      , 0.58058608,\n",
       "        0.77090909, 0.69707602, 0.69417989, 0.36205882, 0.68904762,\n",
       "        0.60320513, 0.74444444, 0.70095238, 0.6798419 , 0.56761905,\n",
       "        0.57670498, 0.53736185, 0.69965035, 0.65261438, 0.70555556,\n",
       "        0.38751306, 0.70274725, 0.50496699, 0.77090909, 0.70261438,\n",
       "        0.66545455, 0.34126984, 0.71125   , 0.58095238, 0.7315508 ,\n",
       "        0.69761905, 0.6469697 , 0.44029304, 0.66545455, 0.58202703,\n",
       "        0.70142857, 0.67036199, 0.64415584, 0.49278846, 0.65776398,\n",
       "        0.6485755 , 0.74965035, 0.70261438, 0.63545455, 0.55666667,\n",
       "        0.69654378, 0.71428571, 0.73939394, 0.69707602, 0.64347826,\n",
       "        0.59220126, 0.59583333, 0.62857143, 0.69415584, 0.60369532,\n",
       "        0.56374269, 0.61833542, 0.74152047, 0.72      , 0.75142857,\n",
       "        0.66269841, 0.6334267 , 0.43179487, 0.72545455, 0.66703704,\n",
       "        0.77090909, 0.70261438, 0.55372549, 0.57562112, 0.56444444,\n",
       "        0.62501672, 0.70915751, 0.59929972, 0.58484848, 0.65714286,\n",
       "        0.75776398, 0.74347826, 0.75692308, 0.66215686, 0.6       ,\n",
       "        0.44673401, 0.67347826, 0.76428571, 0.75606061, 0.70555556]),\n",
       " 'split3_test_score': array([0.05923386, 0.09175021, 0.07431969, 0.07519286, 0.25856397,\n",
       "        0.13442949, 0.06486065, 0.06244867, 0.07591931, 0.07211289,\n",
       "        0.14280364, 0.11179751, 0.05195018, 0.05935852, 0.07303779,\n",
       "        0.06425296, 0.11616442, 0.0831508 , 0.10487266, 0.07901663,\n",
       "        0.09186134, 0.08473575, 0.26366013, 0.14188011, 0.08282484,\n",
       "        0.05735799, 0.08147715, 0.08020756, 0.17367508, 0.11726563,\n",
       "        0.05510415, 0.05127607, 0.08269516, 0.06244626, 0.14103448,\n",
       "        0.09013158, 0.07891464, 0.07361542, 0.08762073, 0.08377888,\n",
       "        0.26409934, 0.14317133, 0.06500277, 0.04983277, 0.11467739,\n",
       "        0.06349322, 0.17971487, 0.11870268, 0.07585859, 0.06026299,\n",
       "        0.06008083, 0.06701495, 0.14268545, 0.11006983, 0.11697375,\n",
       "        0.09575863, 0.10685728, 0.07729739, 0.26392975, 0.14677362,\n",
       "        0.11420455, 0.0626527 , 0.08855082, 0.07674083, 0.18154568,\n",
       "        0.14027379, 0.09590106, 0.05353488, 0.07380735, 0.0722387 ,\n",
       "        0.14858482, 0.11141103, 0.11915182, 0.09080605, 0.1135175 ,\n",
       "        0.08290092, 0.26186274, 0.15600703, 0.09638309, 0.07715121,\n",
       "        0.11352807, 0.06746346, 0.17743384, 0.15200366, 0.07491689,\n",
       "        0.0652376 , 0.08694212, 0.06990583, 0.18402686, 0.13842234]),\n",
       " 'split4_test_score': array([0.28941794, 0.58200885, 0.62026619, 0.67142857, 0.72135458,\n",
       "        0.66888084, 0.55213196, 0.52644799, 0.66369527, 0.61691087,\n",
       "        0.72220367, 0.68884712, 0.53511405, 0.63701156, 0.61823287,\n",
       "        0.59668367, 0.70762877, 0.63579432, 0.64574423, 0.42490372,\n",
       "        0.62516349, 0.68127789, 0.70326826, 0.68434066, 0.5198985 ,\n",
       "        0.64955531, 0.63645766, 0.70333333, 0.70572466, 0.68552532,\n",
       "        0.58646459, 0.26355997, 0.65777422, 0.60754579, 0.72491805,\n",
       "        0.65470425, 0.71273801, 0.43757696, 0.64027516, 0.65443485,\n",
       "        0.67409297, 0.64627159, 0.55351125, 0.49251633, 0.66382623,\n",
       "        0.64439495, 0.70572466, 0.68234819, 0.58009768, 0.3510989 ,\n",
       "        0.62034923, 0.62096861, 0.69447016, 0.68455066, 0.63060558,\n",
       "        0.63224078, 0.68089473, 0.69321966, 0.67359149, 0.61140764,\n",
       "        0.56481401, 0.30528265, 0.67464202, 0.52896024, 0.69139344,\n",
       "        0.68240741, 0.61406632, 0.53030328, 0.60484694, 0.61873766,\n",
       "        0.69384256, 0.68757541, 0.56693122, 0.52385621, 0.70083194,\n",
       "        0.73050675, 0.65426774, 0.59331066, 0.65429801, 0.18711509,\n",
       "        0.64454291, 0.55803987, 0.70362223, 0.68056743, 0.64563492,\n",
       "        0.66916787, 0.55533601, 0.61835772, 0.70519687, 0.67743879]),\n",
       " 'split5_test_score': array([0.0843592 , 0.21011246, 0.15261271, 0.08309528, 0.17940931,\n",
       "        0.16681871, 0.10225456, 0.09435816, 0.13281679, 0.0782926 ,\n",
       "        0.2029145 , 0.11286128, 0.08208764, 0.1025035 , 0.12330321,\n",
       "        0.07309582, 0.19704563, 0.09429672, 0.12169316, 0.09987211,\n",
       "        0.13721543, 0.08882258, 0.18322911, 0.20799077, 0.11013611,\n",
       "        0.08298028, 0.10298206, 0.09551721, 0.20431517, 0.12585141,\n",
       "        0.08916356, 0.08857806, 0.09742617, 0.07063663, 0.20189112,\n",
       "        0.10198727, 0.11599219, 0.11325798, 0.13404683, 0.10440892,\n",
       "        0.17643141, 0.22241453, 0.1189322 , 0.0882413 , 0.11042492,\n",
       "        0.0911611 , 0.21782107, 0.15266448, 0.07845832, 0.09296378,\n",
       "        0.10756599, 0.07991821, 0.22031952, 0.11723143, 0.13246851,\n",
       "        0.13465086, 0.1825786 , 0.10147596, 0.16908921, 0.25499611,\n",
       "        0.0917617 , 0.12867869, 0.11349497, 0.09160536, 0.20613024,\n",
       "        0.1836864 , 0.08425845, 0.09160634, 0.09677713, 0.09177598,\n",
       "        0.20563131, 0.1372162 , 0.15257298, 0.10920039, 0.137891  ,\n",
       "        0.13405937, 0.16303309, 0.27509771, 0.13302072, 0.094358  ,\n",
       "        0.10953131, 0.0949853 , 0.18856647, 0.20850405, 0.1149374 ,\n",
       "        0.20175139, 0.08433906, 0.09054075, 0.23595392, 0.16304192]),\n",
       " 'split6_test_score': array([0.42597891, 0.38175973, 0.60325345, 0.53327473, 0.72292603,\n",
       "        0.54990076, 0.46615215, 0.4385826 , 0.58377165, 0.5624947 ,\n",
       "        0.70540556, 0.61242504, 0.39117298, 0.53163165, 0.57310227,\n",
       "        0.40494952, 0.66736793, 0.618125  , 0.4586544 , 0.51810606,\n",
       "        0.62448854, 0.57144303, 0.72096459, 0.52900661, 0.44900676,\n",
       "        0.28453945, 0.58635161, 0.50728075, 0.6905987 , 0.6047552 ,\n",
       "        0.37322194, 0.27657372, 0.5741836 , 0.52203668, 0.68973939,\n",
       "        0.65313535, 0.48068672, 0.32909551, 0.60667252, 0.56911142,\n",
       "        0.68582251, 0.47592275, 0.37618109, 0.45398411, 0.60526638,\n",
       "        0.50950166, 0.66899406, 0.55573042, 0.44813686, 0.44703337,\n",
       "        0.54793714, 0.53607644, 0.69310121, 0.63263657, 0.56448718,\n",
       "        0.46734347, 0.6112534 , 0.60286663, 0.62297924, 0.46700669,\n",
       "        0.56357986, 0.50573049, 0.58812952, 0.4873808 , 0.69274406,\n",
       "        0.57054545, 0.44761069, 0.53970567, 0.51728779, 0.54531873,\n",
       "        0.70177489, 0.59171823, 0.63102573, 0.5225681 , 0.61451816,\n",
       "        0.63075911, 0.60387198, 0.46207876, 0.49340384, 0.5530672 ,\n",
       "        0.63395332, 0.547245  , 0.71228697, 0.54554368, 0.57964964,\n",
       "        0.48705615, 0.56868084, 0.53734577, 0.70185829, 0.58879242]),\n",
       " 'split7_test_score': array([0.33609585, 0.32581431, 0.35732527, 0.36005753, 0.33954899,\n",
       "        0.35283555, 0.34908983, 0.33500471, 0.368296  , 0.35749502,\n",
       "        0.34613089, 0.35047979, 0.14431223, 0.11042844, 0.35741209,\n",
       "        0.34619139, 0.34983921, 0.34047344, 0.34726668, 0.33325056,\n",
       "        0.35644159, 0.3395759 , 0.29721127, 0.35125002, 0.3834922 ,\n",
       "        0.21988863, 0.36231253, 0.34278149, 0.34572257, 0.34751991,\n",
       "        0.23110635, 0.32208361, 0.3526889 , 0.33241282, 0.34771406,\n",
       "        0.33908175, 0.33085809, 0.27429904, 0.35009781, 0.34472452,\n",
       "        0.26059131, 0.31568135, 0.42640428, 0.32018152, 0.35496483,\n",
       "        0.33326354, 0.34770067, 0.34635763, 0.27874332, 0.09334054,\n",
       "        0.32989209, 0.35024753, 0.35023368, 0.33965906, 0.26365435,\n",
       "        0.32583073, 0.26524862, 0.33961793, 0.26025288, 0.29279121,\n",
       "        0.25709707, 0.34241564, 0.3357514 , 0.33073629, 0.33819273,\n",
       "        0.34679905, 0.33386122, 0.19300193, 0.33403906, 0.33982729,\n",
       "        0.34408338, 0.34220139, 0.33317705, 0.31828232, 0.29069444,\n",
       "        0.33750482, 0.25880817, 0.28450785, 0.28910325, 0.27878917,\n",
       "        0.32970342, 0.33731592, 0.3348108 , 0.34474329, 0.33826218,\n",
       "        0.21410391, 0.2958087 , 0.32882243, 0.34298967, 0.34320503]),\n",
       " 'split8_test_score': array([0.14239435, 0.17414549, 0.14983829, 0.15209599, 0.11472923,\n",
       "        0.16186331, 0.18063717, 0.24666381, 0.12705792, 0.13155212,\n",
       "        0.14557922, 0.1519924 , 0.17259165, 0.18114844, 0.14649122,\n",
       "        0.13045106, 0.15039034, 0.1498255 , 0.13714875, 0.18268681,\n",
       "        0.17081322, 0.18209857, 0.10744489, 0.17416282, 0.16378435,\n",
       "        0.14688753, 0.15199212, 0.13679068, 0.1421174 , 0.15934193,\n",
       "        0.18260449, 0.12369422, 0.18673737, 0.12851393, 0.15520681,\n",
       "        0.15813008, 0.2544723 , 0.24351958, 0.1689222 , 0.21221109,\n",
       "        0.09714704, 0.15367953, 0.11255624, 0.26144802, 0.18546336,\n",
       "        0.16109259, 0.14113717, 0.17263071, 0.31193964, 0.2491078 ,\n",
       "        0.16373749, 0.15280553, 0.15806882, 0.16202458, 0.23349813,\n",
       "        0.21143157, 0.18214066, 0.19897185, 0.08637737, 0.16979624,\n",
       "        0.15486761, 0.17620417, 0.16161136, 0.16057263, 0.13600001,\n",
       "        0.16328148, 0.15215289, 0.19220177, 0.17841672, 0.28148656,\n",
       "        0.14933558, 0.15432768, 0.17161321, 0.23884006, 0.17533688,\n",
       "        0.28060573, 0.08197329, 0.16717295, 0.25894894, 0.24296622,\n",
       "        0.1770649 , 0.15182404, 0.12912191, 0.1643078 , 0.2651997 ,\n",
       "        0.19725009, 0.16778476, 0.28658832, 0.14463461, 0.17895041]),\n",
       " 'split9_test_score': array([0.28740131, 0.30251658, 0.40467292, 0.408874  , 0.40848805,\n",
       "        0.37913578, 0.34995758, 0.19065668, 0.41435092, 0.43031556,\n",
       "        0.41592661, 0.3952332 , 0.44037669, 0.19025889, 0.39339056,\n",
       "        0.42740562, 0.41392325, 0.41356978, 0.45211358, 0.47181241,\n",
       "        0.40083159, 0.40445984, 0.40835064, 0.38080698, 0.35815752,\n",
       "        0.44242634, 0.41932851, 0.42286363, 0.39669936, 0.38787339,\n",
       "        0.27423659, 0.31008878, 0.40178253, 0.40059078, 0.40914157,\n",
       "        0.3944769 , 0.46136782, 0.34372884, 0.3853686 , 0.38352186,\n",
       "        0.40733396, 0.38483132, 0.38845521, 0.32511898, 0.40717151,\n",
       "        0.44265646, 0.39344199, 0.38228027, 0.50952265, 0.37635168,\n",
       "        0.41601965, 0.44188362, 0.39402859, 0.38926259, 0.34292184,\n",
       "        0.30087823, 0.37634686, 0.37980571, 0.34823   , 0.38633647,\n",
       "        0.45374231, 0.32873825, 0.38421638, 0.42603374, 0.38676523,\n",
       "        0.38203279, 0.41800466, 0.19225525, 0.38847319, 0.39386617,\n",
       "        0.38640068, 0.38245924, 0.42956384, 0.52476567, 0.39409841,\n",
       "        0.38346211, 0.33370472, 0.38536716, 0.34380741, 0.35730493,\n",
       "        0.40706387, 0.4116992 , 0.39389264, 0.38397326, 0.40538453,\n",
       "        0.41993258, 0.41725539, 0.43257757, 0.39041109, 0.38203516]),\n",
       " 'mean_test_score': array([0.30776033, 0.33438095, 0.3992693 , 0.37569116, 0.44073962,\n",
       "        0.40098829, 0.35422678, 0.31583658, 0.38868108, 0.36683282,\n",
       "        0.44951953, 0.40762583, 0.31957152, 0.28418241, 0.38643865,\n",
       "        0.34119849, 0.44406579, 0.39706433, 0.36992819, 0.35428848,\n",
       "        0.39681621, 0.37904103, 0.42596978, 0.40582071, 0.34722218,\n",
       "        0.27662457, 0.38849778, 0.36226168, 0.44323206, 0.41017834,\n",
       "        0.31329805, 0.27727116, 0.38946191, 0.34538043, 0.44847475,\n",
       "        0.40303912, 0.36466304, 0.3092506 , 0.39909019, 0.37781492,\n",
       "        0.41085632, 0.39477904, 0.33550014, 0.32209296, 0.39584512,\n",
       "        0.37519717, 0.43861795, 0.40445027, 0.35701114, 0.26154132,\n",
       "        0.38261797, 0.3714457 , 0.44467028, 0.40798621, 0.37448677,\n",
       "        0.37669599, 0.3870506 , 0.3970595 , 0.38521816, 0.38526431,\n",
       "        0.35699187, 0.32634055, 0.40394562, 0.3659307 , 0.42712642,\n",
       "        0.40633607, 0.36332227, 0.31018179, 0.38220512, 0.37308616,\n",
       "        0.43796921, 0.40893406, 0.38470722, 0.38467614, 0.38582255,\n",
       "        0.41495367, 0.36965394, 0.37076302, 0.38066627, 0.32954709,\n",
       "        0.40877827, 0.39157652, 0.42754295, 0.40897117, 0.38796343,\n",
       "        0.35983477, 0.37644247, 0.39483944, 0.44136793, 0.41007698]),\n",
       " 'std_test_score': array([0.18059339, 0.1759984 , 0.20221319, 0.20109772, 0.21376773,\n",
       "        0.19114534, 0.2087571 , 0.16509185, 0.21378952, 0.20130259,\n",
       "        0.23216606, 0.21594494, 0.20097195, 0.18398102, 0.20485364,\n",
       "        0.18737169, 0.23110393, 0.21648128, 0.19928412, 0.1722911 ,\n",
       "        0.19401048, 0.19670673, 0.21086494, 0.18349936, 0.18463249,\n",
       "        0.16954537, 0.21411329, 0.1957289 , 0.2252097 , 0.21283944,\n",
       "        0.19978508, 0.16107749, 0.21185801, 0.19207849, 0.22880891,\n",
       "        0.21893881, 0.20050348, 0.13032653, 0.20314029, 0.19204989,\n",
       "        0.20705715, 0.17968716, 0.19310485, 0.14737511, 0.20662496,\n",
       "        0.20488221, 0.21489224, 0.20100593, 0.18167411, 0.16056807,\n",
       "        0.20739046, 0.21152299, 0.22515536, 0.21530775, 0.18812859,\n",
       "        0.18155674, 0.19104176, 0.20791655, 0.2018335 , 0.15903807,\n",
       "        0.17965431, 0.16331632, 0.22059148, 0.20175396, 0.21294721,\n",
       "        0.1921935 , 0.18960826, 0.17852499, 0.20491885, 0.19049609,\n",
       "        0.22527754, 0.21281296, 0.18490169, 0.17770446, 0.20162184,\n",
       "        0.20637354, 0.2024755 , 0.14683563, 0.17756679, 0.18272339,\n",
       "        0.21800552, 0.21782215, 0.22057155, 0.18569569, 0.18648116,\n",
       "        0.17343323, 0.19840626, 0.21032022, 0.21549741, 0.19972468]),\n",
       " 'rank_test_score': array([86, 77, 28, 55,  7, 27, 72, 82, 38, 63,  1, 21, 81, 87, 42, 75,  4,\n",
       "        30, 61, 71, 32, 51, 12, 23, 73, 89, 39, 67,  5, 15, 83, 88, 37, 74,\n",
       "         2, 26, 65, 85, 29, 52, 14, 35, 76, 80, 33, 56,  8, 24, 69, 90, 48,\n",
       "        59,  3, 20, 57, 53, 41, 31, 45, 44, 70, 79, 25, 64, 11, 22, 66, 84,\n",
       "        49, 58,  9, 18, 46, 47, 43, 13, 62, 60, 50, 78, 19, 36, 10, 17, 40,\n",
       "        68, 54, 34,  6, 16])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_AUC(result):\n",
    "    from sklearn.utils import resample\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n_iter = 10000\n",
    "    roc_auc = list()\n",
    "    prc_auc = list()\n",
    "\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result_sample = resample(result, n_samples = len(result),random_state=i)\n",
    "        \n",
    "        #Calculating AUROC for each sample\n",
    "        y_ACTUAL= result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        roc_auc.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "        #calculate AUPRC for each sample\n",
    "        y_ACTUAL = result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        yhat = result_sample['pred_label']\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        prc_auc.append(metrics.auc(recall,precision))\n",
    "    \n",
    "    return roc_auc, prc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_nn, pr_auc_nn = bootstrapped_AUC(results_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_nn</th>\n",
       "      <th>pr_auc_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.841526</td>\n",
       "      <td>0.446239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031096</td>\n",
       "      <td>0.076540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.688930</td>\n",
       "      <td>0.113871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5%</th>\n",
       "      <td>0.777095</td>\n",
       "      <td>0.291160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.842684</td>\n",
       "      <td>0.448432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5%</th>\n",
       "      <td>0.898288</td>\n",
       "      <td>0.589538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.727022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc_nn     pr_auc_nn\n",
       "count  10000.000000  10000.000000\n",
       "mean       0.841526      0.446239\n",
       "std        0.031096      0.076540\n",
       "min        0.688930      0.113871\n",
       "2.5%       0.777095      0.291160\n",
       "50%        0.842684      0.448432\n",
       "97.5%      0.898288      0.589538\n",
       "max        0.935709      0.727022"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'roc_auc_nn': roc_auc_nn,\n",
    "        'pr_auc_nn': pr_auc_nn,\n",
    "       }\n",
    "pd.DataFrame(dict).describe(percentiles=[0.025,0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Model and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/models/nn_pipeline.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "# Save the Keras model first:\n",
    "model.best_estimator_.named_steps['classifier'].model.save(output_path+'nn_model.h5')\n",
    "\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "dump(model.best_estimator_.named_steps['preprocessor'], output_path+'nn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

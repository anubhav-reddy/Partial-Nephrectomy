{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'H:\\RediMinds\\VCQI'\n",
    "train = pd.read_csv(input_path+\"\\VCQI_clean_train.csv\")\n",
    "test = pd.read_csv(input_path+\"\\VCQI_clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'INTRA_OP_COMPLICATIONS'\n",
    "x_train = train.drop(labels= target, axis = 'columns').copy()\n",
    "y_train = train[target].copy()\n",
    "x_test = test.drop(labels= target, axis = 'columns').copy()\n",
    "y_test = test[target].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% pos labels train 0.05\n",
      "% pos labels test 0.05\n"
     ]
    }
   ],
   "source": [
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Cataegorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ONE HOT CODE data for training\n",
    "\n",
    "# Create dummy variables\n",
    "with open (input_path+'\\cat_col', 'rb') as fp:\n",
    "    cat_col = pickle.load(fp)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "\n",
    "one_hot_encoded_array = encoder.fit_transform(x_train[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_train_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_train = x_train.merge(x_train_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_train = x_train.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "one_hot_encoded_array = encoder.transform(x_test[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_test_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_test = x_test.merge(x_test_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_test = x_test.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in trainset 1985\n",
      "Number records in testset 852\n",
      "% pos labels train 0.05\n",
      "% pos labels test 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in trainset {}\".format(len(x_train)))\n",
    "print(\"Number records in testset {}\".format(len(x_test)))\n",
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for logist Classifier\n",
    "sm = SMOTE(random_state=2)\n",
    "numeric_features = x_train.select_dtypes('float').columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(dropout_rate, neurons, learning_rate):\n",
    "    from numpy.random import seed\n",
    "    seed(123)\n",
    "    from tensorflow.random import set_seed\n",
    "    set_seed(123)\n",
    "    tf.keras.backend.clear_session()\n",
    "   \n",
    "    # input layer\n",
    "    input_layer = keras.layers.Input(shape=(x_train.shape[1],), name = \"input_layer\")\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_1',activation='relu')(input_layer)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_1', seed = 42)(x)\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_2',activation='relu')(x)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_2', seed = 42)(x)\n",
    "    main_output = keras.layers.Dense(1, activation='sigmoid',name='main_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs= input_layer, outputs=main_output)\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.AUC(curve = 'ROC',name = 'AUC_ROC'),\n",
    "                           tf.keras.metrics.AUC(curve = 'PR', name = 'AUC_PR')],\n",
    "                  )\n",
    "\n",
    "    # Keras callback. The patience parameter is the amount of epochs to check for improvement\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=nn_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "parameter_dist = {'classifier__dropout_rate':[0.2,0.3, 0.4, 0.5],\n",
    "                  'classifier__epochs':[20],\n",
    "                  'classifier__neurons':[128],\n",
    "                  'classifier__learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "                 }\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('SMOTE', sm),\n",
    "                      ('classifier', model)])\n",
    "model = GridSearchCV(clf,parameter_dist,n_jobs= 1,scoring= 'roc_auc', cv = 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 20.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('scaler',\n",
       "                                                                                          StandardScaler(copy=True,\n",
       "                                                                                                         with_mean=True,\n",
       "                                                                                                         with_std=True))],\n",
       "                                                                                  verbose=False),\n",
       "                                                                         ['AGEATSURGERY...\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000026D0EE52EF0>)],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'classifier__dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
       "                         'classifier__epochs': [20],\n",
       "                         'classifier__learning_rate': [0.01, 0.005, 0.001,\n",
       "                                                       0.0005, 0.0001],\n",
       "                         'classifier__neurons': [128]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min',restore_best_weights=True)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = pd.DataFrame(model.predict(x_test), columns=['pred_label'])\n",
    "results_nn['pred_prob'] =  pd.DataFrame(model.predict_proba(x_test))[1]\n",
    "results_nn['true_label'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.358539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.892321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.142544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.731510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.151720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.239320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.518325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.157397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.185147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.579845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>0.436653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0</td>\n",
       "      <td>0.069537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>0.747577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1</td>\n",
       "      <td>0.653266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0</td>\n",
       "      <td>0.246238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0</td>\n",
       "      <td>0.145091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0</td>\n",
       "      <td>0.477065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1</td>\n",
       "      <td>0.656689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_label  pred_prob  true_label\n",
       "0             0   0.358539           0\n",
       "1             0   0.000112           0\n",
       "2             0   0.002901           0\n",
       "3             0   0.012583           0\n",
       "4             0   0.000142           0\n",
       "5             1   0.793558           0\n",
       "6             0   0.000013           0\n",
       "7             0   0.008349           0\n",
       "8             1   0.892321           0\n",
       "9             0   0.142544           0\n",
       "10            0   0.016772           0\n",
       "11            0   0.000036           0\n",
       "12            1   0.913462           0\n",
       "13            0   0.004326           0\n",
       "14            0   0.000014           0\n",
       "15            1   0.731510           0\n",
       "16            0   0.000387           0\n",
       "17            0   0.116393           0\n",
       "18            0   0.151720           0\n",
       "19            0   0.000027           0\n",
       "20            0   0.008101           0\n",
       "21            0   0.239320           0\n",
       "22            1   0.518325           0\n",
       "23            0   0.257100           0\n",
       "24            0   0.157397           0\n",
       "25            0   0.008720           0\n",
       "26            0   0.000035           0\n",
       "27            0   0.185147           0\n",
       "28            0   0.011714           0\n",
       "29            1   0.579845           0\n",
       "..          ...        ...         ...\n",
       "822           0   0.009939           0\n",
       "823           0   0.000004           0\n",
       "824           0   0.436653           0\n",
       "825           0   0.069537           0\n",
       "826           0   0.000270           0\n",
       "827           0   0.054892           0\n",
       "828           0   0.013370           0\n",
       "829           0   0.000030           0\n",
       "830           0   0.005402           0\n",
       "831           0   0.307727           0\n",
       "832           0   0.000016           0\n",
       "833           0   0.030397           0\n",
       "834           1   0.747577           0\n",
       "835           0   0.346408           0\n",
       "836           0   0.030183           0\n",
       "837           1   0.653266           0\n",
       "838           0   0.315962           0\n",
       "839           0   0.382495           0\n",
       "840           0   0.050177           0\n",
       "841           0   0.000017           0\n",
       "842           0   0.246238           0\n",
       "843           0   0.002340           0\n",
       "844           0   0.000008           0\n",
       "845           0   0.145091           0\n",
       "846           0   0.477065           0\n",
       "847           0   0.000004           0\n",
       "848           0   0.000034           0\n",
       "849           0   0.007091           0\n",
       "850           0   0.005947           0\n",
       "851           1   0.656689           0\n",
       "\n",
       "[852 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Balanced Accuracy: \n",
      "0.7494708994708994\n",
      "\n",
      " Confusion Matrix : \n",
      "[[732  78]\n",
      " [ 17  25]]\n",
      "\n",
      " Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       810\n",
      "           1       0.24      0.60      0.34        42\n",
      "\n",
      "    accuracy                           0.89       852\n",
      "   macro avg       0.61      0.75      0.64       852\n",
      "weighted avg       0.94      0.89      0.91       852\n",
      "\n",
      "\n",
      " AUC-ROC: \n",
      "0.8389182833627278\n",
      "\n",
      " PR-ROC: \n",
      "0.3628650046890598\n"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork Score Raw Data\n",
    "print(\"\\n Model Balanced Accuracy: \\n\" + str(metrics.balanced_accuracy_score(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Confusion Matrix : \\n\"+str(metrics.confusion_matrix(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Classification Report: \\n\"+ str(metrics.classification_report(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n AUC-ROC: \\n\"+ str(metrics.roc_auc_score(results_nn['true_label'], results_nn['pred_prob'])))\n",
    "\n",
    "\n",
    "def calc_aucpr_data(result):\n",
    "    y_ACTUAL = result['true_label']\n",
    "    scores_prob = result['pred_prob']\n",
    "    yhat = result['pred_label']\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "    prc_auc = metrics.auc(recall,precision)\n",
    "    return prc_auc\n",
    "\n",
    "print(\"\\n PR-ROC: \\n\"+ str(calc_aucpr_data(results_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_AUC(result):\n",
    "    from sklearn.utils import resample\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n_iter = 10000\n",
    "    roc_auc = list()\n",
    "    prc_auc = list()\n",
    "\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result_sample = resample(result, n_samples = len(result),random_state=i)\n",
    "        \n",
    "        #Calculating AUROC for each sample\n",
    "        y_ACTUAL= result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        roc_auc.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "        #calculate AUPRC for each sample\n",
    "        y_ACTUAL = result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        yhat = result_sample['pred_label']\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        prc_auc.append(metrics.auc(recall,precision))\n",
    "    \n",
    "    return roc_auc, prc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_nn, pr_auc_nn = bootstrapped_AUC(results_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_nn</th>\n",
       "      <th>pr_auc_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.839307</td>\n",
       "      <td>0.367749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.080376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.690972</td>\n",
       "      <td>0.104345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5%</th>\n",
       "      <td>0.772586</td>\n",
       "      <td>0.215942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.840633</td>\n",
       "      <td>0.365784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5%</th>\n",
       "      <td>0.898181</td>\n",
       "      <td>0.528851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.681194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc_nn     pr_auc_nn\n",
       "count  10000.000000  10000.000000\n",
       "mean       0.839307      0.367749\n",
       "std        0.032196      0.080376\n",
       "min        0.690972      0.104345\n",
       "2.5%       0.772586      0.215942\n",
       "50%        0.840633      0.365784\n",
       "97.5%      0.898181      0.528851\n",
       "max        0.942000      0.681194"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'roc_auc_nn': roc_auc_nn,\n",
    "        'pr_auc_nn': pr_auc_nn,\n",
    "       }\n",
    "pd.DataFrame(dict).describe(percentiles=[0.025,0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Model and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/models/nn_preprocessor_pipeline.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "# Save the Keras model first:\n",
    "model.best_estimator_.named_steps['classifier'].model.save(output_path+'SMOTE_nn_model.h5')\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "dump(model.best_estimator_.named_steps['SMOTE'], output_path+'nn_SMOTE_pipeline.pkl')\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "dump(model.best_estimator_.named_steps['preprocessor'], output_path+'nn_preprocessor_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

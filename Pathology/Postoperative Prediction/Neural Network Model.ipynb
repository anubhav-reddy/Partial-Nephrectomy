{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'H:\\RediMinds\\VCQI'\n",
    "train = pd.read_csv(input_path+\"\\VCQI_clean_train_30_day_complications.csv\")\n",
    "test = pd.read_csv(input_path+\"\\VCQI_clean_test_30_day_complications.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'POSTOP_COMPLICATIONS'\n",
    "x_train = train.drop(labels=target, axis = 'columns').copy()\n",
    "y_train = train[target].copy()\n",
    "x_test = test.drop(labels=target, axis = 'columns').copy()\n",
    "y_test = test[target].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% pos labels train 0.21\n",
      "% pos labels test 0.21\n"
     ]
    }
   ],
   "source": [
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Cataegorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ONE HOT CODE data for training\n",
    "\n",
    "# Create dummy variables\n",
    "with open (input_path+'\\cat_col_30_day_complications', 'rb') as fp:\n",
    "    cat_col = pickle.load(fp)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "\n",
    "one_hot_encoded_array = encoder.fit_transform(x_train[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_train_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_train = x_train.merge(x_train_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_train = x_train.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "one_hot_encoded_array = encoder.transform(x_test[cat_col]).toarray()\n",
    "column_name = encoder.get_feature_names(cat_col)\n",
    "x_test_OHE =  pd.DataFrame(one_hot_encoded_array, columns= column_name)\n",
    "x_test = x_test.merge(x_test_OHE, how = 'left', left_index = True, right_index =True) # create dummy variables\n",
    "x_test = x_test.drop(labels = cat_col, axis = 'columns') # drop original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in trainset 984\n",
      "Number records in testset 422\n",
      "% pos labels train 0.21\n",
      "% pos labels test 0.21\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in trainset {}\".format(len(x_train)))\n",
    "print(\"Number records in testset {}\".format(len(x_test)))\n",
    "print('% pos labels train {:.2f}'.format(y_train.sum()/len(y_train)))\n",
    "print('% pos labels test {:.2f}'.format(y_test.sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for logist Classifier\n",
    "numeric_features = x_train.select_dtypes('float').columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.3883495145631066, 1: 0.6323907455012854}\n"
     ]
    }
   ],
   "source": [
    "# compute weight to account for class imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=y_train.unique(), y = y_train)\n",
    "weights\n",
    "class_weight = {0: weights[0] , 1: weights[1]}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(dropout_rate, neurons, learning_rate):\n",
    "    from numpy.random import seed\n",
    "    seed(123)\n",
    "    tf.random.set_seed(123)\n",
    "    tf.keras.backend.clear_session()\n",
    "   \n",
    "    # input layer\n",
    "    input_layer = keras.layers.Input(shape=(x_train.shape[1],), name = \"input_layer\")\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_1',activation='relu')(input_layer)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_1', seed = 42)(x)\n",
    "    x = keras.layers.Dense(neurons, name = 'Dense_2',activation='relu')(x)\n",
    "    x = keras.layers.Dropout(dropout_rate, name=  'Dropout_2', seed = 42)(x)\n",
    "    main_output = keras.layers.Dense(1, activation='sigmoid',name='main_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs= input_layer, outputs=main_output)\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.AUC(curve = 'ROC',name = 'AUC_ROC'),\n",
    "                           tf.keras.metrics.AUC(curve = 'PR', name = 'AUC_PR')],\n",
    "                  )\n",
    "\n",
    "    # Keras callback. The patience parameter is the amount of epochs to check for improvement\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=nn_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "parameter_dist = {'classifier__dropout_rate':[0.1,0.2,0.3,0.4,0.5],\n",
    "                  'classifier__epochs':[10,20,30],\n",
    "                  'classifier__neurons':[128, 256],\n",
    "                  'classifier__learning_rate': [0.01, 0.001, 0.0001],\n",
    "                 }\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      #('pca',PCA()),\n",
    "                      ('classifier', model)])\n",
    "model = GridSearchCV(clf,parameter_dist,n_jobs= 1,scoring= 'average_precision', cv = 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 900 out of 900 | elapsed: 51.9min finished\n",
      "C:\\Users\\anubhav\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('scaler',\n",
       "                                                                                          StandardScaler(copy=True,\n",
       "                                                                                                         with_mean=True,\n",
       "                                                                                                         with_std=True))],\n",
       "                                                                                  verbose=False),\n",
       "                                                                         ['AGEATSURGERY...\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000264AFECD808>)],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'classifier__dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'classifier__epochs': [10, 20, 30],\n",
       "                         'classifier__learning_rate': [0.01, 0.001, 0.0001],\n",
       "                         'classifier__neurons': [128, 256]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='average_precision', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min',restore_best_weights=True)\n",
    "model.fit(x_train,y_train, classifier__class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = pd.DataFrame(model.predict(x_test), columns=['pred_label'])\n",
    "results_nn['pred_prob'] =  pd.DataFrame(model.predict_proba(x_test))[1]\n",
    "results_nn['true_label'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_label  pred_prob  true_label\n",
       "0             1   0.895386           1\n",
       "1             0   0.038000           0\n",
       "2             0   0.003884           0\n",
       "3             1   0.926017           1\n",
       "4             0   0.001948           0\n",
       "..          ...        ...         ...\n",
       "417           1   0.762174           1\n",
       "418           0   0.091294           0\n",
       "419           0   0.005862           1\n",
       "420           0   0.004995           0\n",
       "421           0   0.003190           0\n",
       "\n",
       "[422 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Balanced Accuracy: \n",
      "0.6126969666295509\n",
      "\n",
      " Confusion Matrix : \n",
      "[[322  11]\n",
      " [ 66  23]]\n",
      "\n",
      " Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       333\n",
      "           1       0.68      0.26      0.37        89\n",
      "\n",
      "    accuracy                           0.82       422\n",
      "   macro avg       0.75      0.61      0.63       422\n",
      "weighted avg       0.80      0.82      0.78       422\n",
      "\n",
      "\n",
      " AUC-ROC: \n",
      "0.8337888450248001\n",
      "\n",
      " PR-ROC: \n",
      "0.5979064652188595\n"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork Score Raw Data\n",
    "print(\"\\n Model Balanced Accuracy: \\n\" + str(metrics.balanced_accuracy_score(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Confusion Matrix : \\n\"+str(metrics.confusion_matrix(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n Classification Report: \\n\"+ str(metrics.classification_report(results_nn['true_label'], results_nn['pred_label'])))\n",
    "print(\"\\n AUC-ROC: \\n\"+ str(metrics.roc_auc_score(results_nn['true_label'], results_nn['pred_prob'])))\n",
    "\n",
    "\n",
    "def calc_aucpr_data(result):\n",
    "    y_ACTUAL = result['true_label']\n",
    "    scores_prob = result['pred_prob']\n",
    "    yhat = result['pred_label']\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "    prc_auc = metrics.auc(recall,precision)\n",
    "    return prc_auc\n",
    "\n",
    "print(\"\\n PR-ROC: \\n\"+ str(calc_aucpr_data(results_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_AUC(result):\n",
    "    from sklearn.utils import resample\n",
    "    #from tqdm import tqdm\n",
    "\n",
    "    n_iter = 10000\n",
    "    roc_auc = list()\n",
    "    prc_auc = list()\n",
    "\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result_sample = resample(result, n_samples = len(result),random_state=i)\n",
    "        \n",
    "        #Calculating AUROC for each sample\n",
    "        y_ACTUAL= result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        roc_auc.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "        #calculate AUPRC for each sample\n",
    "        y_ACTUAL = result_sample['true_label']\n",
    "        scores_prob = result_sample['pred_prob']\n",
    "        yhat = result_sample['pred_label']\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(y_ACTUAL, scores_prob, pos_label=1)\n",
    "        prc_auc.append(metrics.auc(recall,precision))\n",
    "    \n",
    "    return roc_auc, prc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_nn, pr_auc_nn = bootstrapped_AUC(results_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_nn</th>\n",
       "      <th>pr_auc_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.834086</td>\n",
       "      <td>0.598821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>0.052551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.734825</td>\n",
       "      <td>0.351332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.5%</td>\n",
       "      <td>0.785063</td>\n",
       "      <td>0.493888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.834934</td>\n",
       "      <td>0.600067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97.5%</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.698902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.910027</td>\n",
       "      <td>0.798171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         roc_auc_nn     pr_auc_nn\n",
       "count  10000.000000  10000.000000\n",
       "mean       0.834086      0.598821\n",
       "std        0.024385      0.052551\n",
       "min        0.734825      0.351332\n",
       "2.5%       0.785063      0.493888\n",
       "50%        0.834934      0.600067\n",
       "97.5%      0.879186      0.698902\n",
       "max        0.910027      0.798171"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'roc_auc_nn': roc_auc_nn,\n",
    "        'pr_auc_nn': pr_auc_nn,\n",
    "       }\n",
    "pd.DataFrame(dict).describe(percentiles=[0.025,0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Model and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/models/nn_pipeline.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "# Save the Keras model first:\n",
    "model.best_estimator_.named_steps['classifier'].model.save(output_path+'nn_model.h5')\n",
    "\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "dump(model.best_estimator_.named_steps['preprocessor'], output_path+'nn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

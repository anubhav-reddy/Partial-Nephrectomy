{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)  \n",
    "#pd.set_option('display.expand_frame_repr', False)\n",
    "#pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prospective dataset\n",
    "df= pd.read_excel('H:/RediMinds/DRMahen/Preethi PN_Data validation_2014-2018.xlsx', sheet_name='PN_Data validation_2014-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of patients and columns in Retrospective dataset\n",
    "print('Number of patients in Combined dataset {}'. format(df.shape[0]))\n",
    "print('Number of variables in Combined dataset {}'. format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index for combined dataset\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose = True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable for INTRA OP complications\n",
    "df['INTRA_OP_COMPLICATIONS'] = 0\n",
    "\n",
    "# selecting indicator == 'Yes' and code vailability or Intra-op Bloos transfusion>1 unit as Intra-op complication\n",
    "df.loc[((df['INTRAOPCOMPLICATIONS'].notnull()) & (df['INTRAOPCOMPLICATION'] == 'Yes'))|(df['INTRAOPTRANSUFUSION']=='>1 Unit') ,['INTRA_OP_COMPLICATIONS']] = 1\n",
    "num_complications = df['INTRA_OP_COMPLICATIONS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number patients with complications\n",
    "print('Total number of patients {}'.format(len(df)))\n",
    "print('Total number of patients with complications {}'.format(num_complications))\n",
    "print('Total % of patients with complications {:.3f}'.format(num_complications/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define numeric columns and replace encoded missing values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns tobre converted to numeric\n",
    "numeric_col_list = ['AGEATSURGERY',\n",
    "'WEIGHT',\n",
    "'HEIGHT',\n",
    "'BMI',\n",
    "'CLINICALSIZEmm',\n",
    "'PREOPHB',\n",
    "'PREOPHT',\n",
    "'PREOPWBC',\n",
    "'PREOPCREAT',\n",
    "'PREOPGFR',\n",
    "'PREOPEGFR',\n",
    "'PREOPERPF',\n",
    "'NOOFLESIONS',\n",
    "'BLOODLOSSml',\n",
    "'POSTOPHB_Day1',\n",
    "'POSTOPHT_Day1',\n",
    "'POSTOPCreat_Day1',\n",
    "'POSTOPEGFR_Day1',\n",
    "'POSTOPWBC_Day1',\n",
    "'POSTOPHB_Day2',\n",
    "'POSTOPHT_Day2',\n",
    "'POSTOPCreat_Day2',\n",
    "'POSTOPEGFR_Day2',\n",
    "'POSTOPWBC_Day2',\n",
    "'POSTOPHB_Day3',\n",
    "'POSTOPHT_Day3',\n",
    "'POSTOPCreat_Day3',\n",
    "'POSTOPEGFR_Day3',\n",
    "'POSTOPWBC_Day3',\n",
    "'LENGTHOFSTAYdays',\n",
    "'PATHOLOGICALTUMORSIZE',\n",
    "'MINTHICKNESSMARGIN',\n",
    "'MAXTHICKNESSMARGIN',\n",
    "'SARCOMATOIDDIFF_A',\n",
    "'NO_OF_NODE_TAKEN',\n",
    "'LASTFOLLOWUPDURATION',\n",
    "'CHARLSONSCORE',\n",
    "'CHARLSONAGEADJUSTSCORE',\n",
    "'PADUASCORE',\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns in numeric_col_list to numeric and invalid values are set NaN \n",
    "for col in numeric_col_list:\n",
    "    df[col]= pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of numeric columns\n",
    "df.describe(include = [np.number]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values such as 999 in the dataframe with NaN\n",
    "df = df.replace([99,999,9999,99999,999999,-99,-999,-9999,-99999,-999999],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing negative numbers in the dataframe with nan as given variables cannot contain negative numbers\n",
    "for col in list(df.select_dtypes('float64')):\n",
    "    df[col] = df[col].apply(lambda x: np.nan if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of numeric columns - to check missing values such as 99, 999, 999 have been replaced\n",
    "df.describe(include = [np.number]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the units for erroroneously entered data\n",
    "def clean_WBC(x):\n",
    "    if len(str(x))<6:\n",
    "        x = x*1000\n",
    "    return x\n",
    "        \n",
    "\n",
    "# if the value of PRE-OP WBC value contains is less the 4 digits then multiply it by 1000\n",
    "df['PREOPWBC'] = df['PREOPWBC'].apply(lambda x: clean_WBC(x))\n",
    "\n",
    "# if the value of POST-OP WBC_Day 1 value contains is less the 4 digits then multiply it by 1000\n",
    "df['POSTOPWBC_Day1'] = df['POSTOPWBC_Day1'].apply(lambda x: clean_WBC(x))\n",
    "\n",
    "# if the value of POST-OP WBC_Day 2 value contains is less the 4 digits then multiply it by 1000\n",
    "df['POSTOPWBC_Day2'] = df['POSTOPWBC_Day2'].apply(lambda x: clean_WBC(x))\n",
    "\n",
    "# if the value of POST-OP WBC_Day 2 value contains is less the 4 digits then multiply it by 1000\n",
    "df['POSTOPWBC_Day3'] = df['POSTOPWBC_Day3'].apply(lambda x: clean_WBC(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the units for erroroneously entered data for PREOPHB\n",
    "df['PREOPHB'] = df['PREOPHB'].apply(lambda x: x*100 if x<10 else x)\n",
    "\n",
    "# Correcting the units for erroroneously entered data for PREOPHB\n",
    "df['PREOPHT'] = df['PREOPHT'].apply(lambda x: x*100 if x<10 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['PROCNAME',\n",
    "'CENTERCODE',\n",
    "'SURGEONCODE',\n",
    "'RECPROGRESS',\n",
    "'GENDER',\n",
    "'MARITALSTATUS',\n",
    "'RACE',\n",
    "'EDUCATION',\n",
    "'ECOG',\n",
    "'SYMPTOMS',\n",
    "'SOLITARYKIDNEY',\n",
    "'TYPEOFSOLITARYKIDNEY',\n",
    "'BILATERALITYOFTUMOR',\n",
    "'SIDEOFTUMOR',\n",
    "'SIDEOFSURGERY',\n",
    "'PREOPMULTIFOCALITY',\n",
    "'FACE',\n",
    "'TUMORlOCATION',\n",
    "\n",
    "'PADUARISK',\n",
    "'POLARLOCATION',\n",
    "'RIMLOCATION',\n",
    "'RENALSINUS',\n",
    "'UCSINVASION',\n",
    "'EXOPHYTICRATE',\n",
    "'CLINICALSIZEGROUP',\n",
    "'CT',\n",
    "'CN',\n",
    "'CM',\n",
    "'R.E.N.A.L.NEPHROSCORE',\n",
    "'R.E.N.A.L.NEPHRORISKSTRATIFICATION',\n",
    "'RADIUSmaximaldiameterincm',\n",
    "'EXOPHYTICENDOPHYTICPROPERTIES',\n",
    "'NEARNESSOFTUMOUR',\n",
    "'ANTERIORORPOSTERIOR',\n",
    "'LOCATIONTOPOLARLINE',\n",
    "'TumorConsistencyonImaging',\n",
    "'BosniakClassification',\n",
    "'ASASCORE',\n",
    "'PARTIALNEPHROINDICATION',\n",
    "'MULTIFOCALITY',\n",
    "'ImagingFeaturesofotherexcisedtumor',\n",
    "'Consistencyoftheotherexcisedtumors',\n",
    "'ACCESS',\n",
    "'DAVINCIMODEL',\n",
    "'ROBOTICSARMS',\n",
    "'ASSISTENTTROCARS',\n",
    "'DUALCONSOLE',\n",
    "'PRIMARYSURGEON',\n",
    "'ISCHEMIA',\n",
    "'CLAMPARTERY',\n",
    "'SELECTIVEARTERIALCLAMPING',\n",
    "'CLAMPVEIN',\n",
    "'EARLYUNCLAMPING',\n",
    "'FLUORESCENCE',\n",
    "'INNERRENORRHAPHY',\n",
    "'OUTERRENORRHAPHY',\n",
    "'UCSREPAIR',\n",
    "'HAEMOSTATICAGENTS',\n",
    "'HAEMOSTATICDetails',\n",
    "'LYMPHNODEDISSECTIONLND',\n",
    "'INTRAOPTRANSUFUSION',\n",
    "'SURGICALCONSIDERATIONS',\n",
    "'INTRAOPCOMPLICATION',\n",
    "'INTRAOPCOMPLICATIONS',\n",
    "'NeedtoConverttoRadicalNephrectomy',\n",
    "'TREATMENTOFCOMPLICATION',\n",
    "'POSTOPCOMPLICATION',\n",
    "'SURGICALCOMPLICATIONS',\n",
    "'NONSURGICALCOMPLICATIONS',\n",
    "'POSTOPTREATMENTOFCOMPLICATION',\n",
    "'CLAVIENGRADE',\n",
    "'MULITIFOCALITY',\n",
    "'PATHOLOGY',\n",
    "'HYSTOTYPEMALIGNANAT',\n",
    "'HYSTOTYPEMALIGNANATYES',\n",
    "'HYSTOTYPEBENIGN',\n",
    "'HYSTOTYPEBENIGNYES',\n",
    "'FUHRMANGRADING',\n",
    "'SARCOMATOIDDIFF',\n",
    "'NECROSIS',\n",
    "'MICROVENOUSINVASION',\n",
    "'UCSINVASION_A',\n",
    "'PERIRENALFATINVASION',\n",
    "'HilarFatInvasion',\n",
    "'SINUSFATINVASION',\n",
    "'MICSCORE',\n",
    "'ADRENALINVASION',\n",
    "'GEROTAINVASION',\n",
    "'RenalVeinInvasion',\n",
    "'VENOUSTHROMBUS',\n",
    "'SURGICALMARGIN',\n",
    "'UNIFOCALMULTIFOCAL',\n",
    "'NO_OF_NODE_POSITIVE',\n",
    "'SITEOFPOSITIVENODE',\n",
    "'TREATMENTPSM',\n",
    "'PT',\n",
    "'PN',\n",
    "'OTHERTUMORS',\n",
    "'LASTFOLLOWUPSTATUS',\n",
    "'LASTFOLLOWUPRECURRENCE',\n",
    "'LASTTREATMENTOFRECURRENCE'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Variables for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables included for Intra-Op complications \n",
    "intra_op_col = [\n",
    "'PATIENTNUMBER',\n",
    "#'PROCNAME',\n",
    "'CENTERCODE',\n",
    "#'SURGEONCODE',\n",
    "#'RECPROGRESS',\n",
    "#'CREATEDDATE',\n",
    "'GENDER',\n",
    "#'DATEOFBIRTH',\n",
    "'AGEATSURGERY',\n",
    "'MARITALSTATUS',\n",
    "'RACE',\n",
    "'EDUCATION',\n",
    "#'WEIGHT',\n",
    "#'HEIGHT',\n",
    "'BMI',\n",
    "'CLINICALSIZEmm',\n",
    "'ECOG',\n",
    "'CHARLSONSCORE',\n",
    "#'CHARLSONAGEADJUSTSCORE',\n",
    "'SYMPTOMS',\n",
    "'SOLITARYKIDNEY',\n",
    "'TYPEOFSOLITARYKIDNEY',\n",
    "'BILATERALITYOFTUMOR',\n",
    "'SIDEOFTUMOR',\n",
    "'SIDEOFSURGERY',\n",
    "'PREOPMULTIFOCALITY',\n",
    "'FACE',\n",
    "'TUMORlOCATION',\n",
    "'PREOPHB',\n",
    "'PREOPHT',\n",
    "'PREOPWBC',\n",
    "'PREOPCREAT',\n",
    "'PREOPGFR',\n",
    "'PREOPEGFR',\n",
    "'PREOPERPF',\n",
    "#'PADUASCORE',\n",
    "'PADUARISK',\n",
    "'POLARLOCATION',\n",
    "'RIMLOCATION',\n",
    "'RENALSINUS',\n",
    "#'UCSINVASION',\n",
    "'EXOPHYTICRATE',\n",
    "'CLINICALSIZEGROUP',\n",
    "'CT',\n",
    "'CN',\n",
    "'CM',\n",
    "#'R.E.N.A.L.NEPHROSCORE',\n",
    "'R.E.N.A.L.NEPHRORISKSTRATIFICATION',\n",
    "'RADIUSmaximaldiameterincm',\n",
    "'EXOPHYTICENDOPHYTICPROPERTIES',\n",
    "'NEARNESSOFTUMOUR',\n",
    "'ANTERIORORPOSTERIOR',\n",
    "'LOCATIONTOPOLARLINE',\n",
    "'TumorConsistencyonImaging',\n",
    "'BosniakClassification',\n",
    "#'DATEOFSURGERY',\n",
    "'ASASCORE',\n",
    "'PARTIALNEPHROINDICATION',\n",
    "'MULTIFOCALITY',\n",
    "'NOOFLESIONS',\n",
    "#'ImagingFeaturesofotherexcisedtumor', #too many categories\n",
    "'Consistencyoftheotherexcisedtumors',\n",
    "#'ACCESS',\n",
    "#'DAVINCIMODEL',\n",
    "#'ROBOTICSARMS',\n",
    "#'ASSISTENTTROCARS',\n",
    "#'DUALCONSOLE',\n",
    "#'PRIMARYSURGEON',\n",
    "#'OPERATIVETIMEmin',\n",
    "#'ISCHEMIA',\n",
    "#'CLAMPARTERY',\n",
    "#'SELECTIVEARTERIALCLAMPING',\n",
    "#'CLAMPVEIN',\n",
    "#'EARLYUNCLAMPING',\n",
    "#'FLUORESCENCE',\n",
    "#'INNERRENORRHAPHY',\n",
    "#'OUTERRENORRHAPHY',\n",
    "#'ISCHEMIATIMEmin',\n",
    "#'UCSREPAIR',\n",
    "#'HAEMOSTATICAGENTS',\n",
    "#'HAEMOSTATICDetails',\n",
    "#'LYMPHNODEDISSECTIONLND',\n",
    "#'BLOODLOSSml',\n",
    "#'INTRAOPTRANSUFUSION',\n",
    "#'SURGICALCONSIDERATIONS',\n",
    "#'INTRAOPCOMPLICATION',\n",
    "#'INTRAOPCOMPLICATIONS',\n",
    "'INTRA_OP_COMPLICATIONS'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intra_op_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting dataframe relevant columsn for analysis\n",
    "df = df[intra_op_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep columns having less than 50% missing data\n",
    "print(\"Total number of columns before removing columns with more than 50% missing data: {}\".format(len(list(df))))\n",
    "\n",
    "df = df[df.columns[df.isnull().mean() <= 0.50]].copy()\n",
    "\n",
    "print(\"Total number of columns left after removing columns with more than 50% missing data: {}\".format(len(list(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'INTRA_OP_COMPLICATIONS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "rs = np.random.RandomState(10)\n",
    "f, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "sns.despine(left=True)\n",
    "sns.boxplot(data = df, y = 'AGEATSURGERY', x = target,ax=axes[0, 0])\n",
    "sns.boxplot(data = df, y = 'BMI', x = target, ax=axes[0, 1])\n",
    "sns.boxplot(data = df, y = 'CLINICALSIZEmm', x = target, ax=axes[0, 2])\n",
    "sns.boxplot(data = df, y = 'PREOPHB', x = target, ax=axes[0, 3])\n",
    "sns.boxplot(data = df, y = 'PREOPHT', x = target, ax=axes[1, 0])\n",
    "sns.boxplot(data = df, y = 'PREOPWBC', x = target, ax=axes[1, 1])\n",
    "sns.boxplot(data = df, y = 'PREOPCREAT', x = target, ax=axes[1, 2])\n",
    "sns.boxplot(data = df, y = 'PREOPEGFR', x = target, ax=axes[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of outliers\n",
    "clean_cols = ['BMI','CLINICALSIZEmm','PREOPHB','PREOPHT','PREOPWBC','PREOPCREAT','PREOPEGFR']\n",
    "for i in clean_cols:\n",
    "    q1 = numeric_stats.loc['25%'][i]\n",
    "    q3 = numeric_stats.loc['75%'][i]\n",
    "    IQR = q3-q1\n",
    "    LL = q1-(1.5*IQR)\n",
    "    UL = q3+(1.5*IQR)\n",
    "    print('{:<14s} {:>4d} {:>4d}'.format(i,len(df.loc[(df[i]>=UL)]),len(df.loc[(df[i]<=LL)])), 'UL-LL {:>4.2f}-{:>4.2f}'.format(UL,LL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing inaccurate readings with missing values\n",
    "clean_cols = ['BMI','CLINICALSIZEmm','PREOPHB','PREOPHT','PREOPWBC','PREOPCREAT','PREOPEGFR']\n",
    "for i in clean_cols:\n",
    "    q1 = numeric_stats.loc['25%'][i]\n",
    "    q3 = numeric_stats.loc['75%'][i]\n",
    "    IQR = q3-q1\n",
    "    LL = q1-(1.5*IQR)\n",
    "    UL = q3+(1.5*IQR)\n",
    "    df.drop(df.loc[(df[i]<=LL)|(df[i]>=UL),[i]].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "rs = np.random.RandomState(10)\n",
    "f, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "sns.despine(left=True)\n",
    "sns.boxplot(data = df, y = 'AGEATSURGERY', x = target,ax=axes[0, 0])\n",
    "sns.boxplot(data = df, y = 'BMI', x = target, ax=axes[0, 1])\n",
    "sns.boxplot(data = df, y = 'CLINICALSIZEmm', x = target, ax=axes[0, 2])\n",
    "sns.boxplot(data = df, y = 'PREOPHB', x = target, ax=axes[0, 3])\n",
    "sns.boxplot(data = df, y = 'PREOPHT', x = target, ax=axes[1, 0])\n",
    "sns.boxplot(data = df, y = 'PREOPWBC', x = target, ax=axes[1, 1])\n",
    "sns.boxplot(data = df, y = 'PREOPCREAT', x = target, ax=axes[1, 2])\n",
    "sns.boxplot(data = df, y = 'PREOPEGFR', x = target, ax=axes[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The percentage of missing data\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number missing values per row\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "missing = {}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    miss_cnt = 0\n",
    "    for col in df.columns:\n",
    "        if pd.isna(df[col][i]) == True:\n",
    "            miss_cnt = miss_cnt+1\n",
    "    df.loc[i,'Missing'] = miss_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of records with over 25% missing data\n",
    "print(\"Total Records {}\".format(len(df)))\n",
    "print(\"Records with >=25% missing data {}\".format(sum(df['Missing']<= round((len(df.columns)-2)*.30))))\n",
    "print(\"Records to be dropped {}\".format(len(df) - sum(df['Missing']<= round((len(df.columns)-2)*.30))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check thenumber of missing values for eahc variables if records with a certain missing threshold were removed\n",
    "df[df['Missing']<= round((len(df.columns)-2)*.30) ].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing patients with more than 75% missing data\n",
    "df = df[df['Missing']<= round((len(df.columns)-2)*.30) ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep columns having less than 10% missing data\n",
    "df = df[df.columns[df.isnull().mean() <= 0.15]].copy()\n",
    "\n",
    "print(\"Total number of columns left after removing columns with missing data: {}\".format(len(list(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of patients with clean data\n",
    "patient_list = df['PATIENTNUMBER'].tolist()\n",
    "with open('output/patient_list.txt', 'w') as f:\n",
    "    for item in patient_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of missing data\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replcaing missing values in categorical column with NA\n",
    "for k in cat_col:\n",
    "    if k in df.columns:\n",
    "        df[k].fillna('NA',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in numerical columns with their respective mean \n",
    "for k in numeric_col_list:\n",
    "    if k in df.columns:\n",
    "        df[k].fillna(round(df[k].mean()), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check unique value in each column of type object\n",
    "unique_count_list = {}\n",
    "\n",
    "for k in cat_col:\n",
    "    if k in df.columns:\n",
    "        unique_count_list.update({k:len(df[k].unique())})\n",
    "\n",
    "unique_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object columns with less than 10 unique values into type category\n",
    "for col in unique_count_list:\n",
    "        df[col] = df[col].astype('category').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features with high number of categories\n",
    "for col in unique_count_list:\n",
    "    if unique_count_list[col]>10:\n",
    "        print(col,unique_count_list[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Number records for predicting intra-op complications: {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes('category').columns:\n",
    "    df[i] = df[i].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit label encoder to each column of type category\n",
    "cat_col =df.select_dtypes('category')\n",
    "df_codes = df.copy()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_dict = {col: LabelEncoder() for col in cat_col }\n",
    "for col in cat_col:\n",
    "    le_dict[col].fit_transform(df_codes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary cantaining mapping of categorical values to numerical values\n",
    "label_mapping = dict()\n",
    "label_mapping = {col: dict(zip(le_dict[col].classes_,le_dict[col].transform(le_dict[col].classes_))) for col in cat_col}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping categorical column values to integer labels\n",
    "for col in cat_col:\n",
    "    df_codes[col] = le_dict[col].transform(df_codes[col]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Stats fot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print median , IQR for numeric columns \n",
    "for i in df.columns:#['AGEATSURGERY','BMI','CLINICALSIZEmm','PREOPHB','PREOPHT','PREOPWBC','PREOPCREAT','PREOPEGFR','NOOFLESIONS']:\n",
    "    if i in numeric_col_list:\n",
    "        print(i, \"{0:.1f} [{1:.1f}-{2:.1f}]\".format(np.median(df[i]),np.percentile(df[i],25),np.percentile(df[i],75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print number of records for each category in categorical columns\n",
    "for i in df_codes.columns:\n",
    "    if i in cat_col:\n",
    "        print(df_codes[i].apply(lambda x: le_dict[i].inverse_transform([x])[0]).value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traget_stats = pd.merge(df_codes[['PATIENTNUMBER']],\n",
    "                        df_ori[['PATIENTNUMBER','INTRAOPCOMPLICATIONS','SURGICALCOMPLICATIONS','NONSURGICALCOMPLICATIONS']], \n",
    "                        left_on='PATIENTNUMBER', \n",
    "                        right_on='PATIENTNUMBER').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget_stats['INTRAOPCOMPLICATIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget_stats['SURGICALCOMPLICATIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget_stats['NONSURGICALCOMPLICATIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.drop(labels=['Missing','PATIENTNUMBER'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.corr()['INTRA_OP_COMPLICATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of patients {}'.format(len(df_codes)))\n",
    "print('% of patients with complications {:.2f}%'.format(sum(df_codes['INTRA_OP_COMPLICATIONS'])/len(df_codes)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'H:\\RediMinds\\VCQI'\n",
    "df_codes.to_csv(output_path+\"\\VCQI_clean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_codes, test_size=0.30, random_state=42, stratify = df_codes['INTRA_OP_COMPLICATIONS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Percentage of complications in trainset\n",
    "train['INTRA_OP_COMPLICATIONS'].sum()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of complications in testset\n",
    "test['INTRA_OP_COMPLICATIONS'].sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test dataset\n",
    "train.to_csv(output_path+\"\\VCQI_clean_train.csv\",index=False)\n",
    "test.to_csv(output_path+\"\\VCQI_clean_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cat_col = df.select_dtypes('category')\n",
    "\n",
    "with open(output_path+'\\cat_col', 'wb') as fp:\n",
    "    pickle.dump(cat_col.columns.to_list(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
